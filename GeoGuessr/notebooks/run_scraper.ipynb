{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_street_view.py\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "# import chromedriver_autoinstaller\n",
    "import pycountry\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import date\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "class RandomStreetViewParser:\n",
    "    \"\"\"\n",
    "    Parser for randomstreetview.com\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, driver_path, width=1024, height=768):\n",
    "        \"\"\"\n",
    "        Create the random user agent driver\n",
    "        \"\"\"\n",
    "        options = Options()\n",
    "        options.add_argument(f\"window-size={width},{height}\")\n",
    "        ua = UserAgent()\n",
    "        user_agent = ua.random\n",
    "        options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "        self.geolocator = Nominatim(user_agent=str(user_agent))\n",
    "\n",
    "        driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
    "        self.driver = driver\n",
    "\n",
    "        # TODO: TECHNICAL DEBT\n",
    "        iso = pd.read_csv(\"../data/utility/iso3166.csv\")\n",
    "        self.name_to_iso_alpha2 = dict(zip(iso[\"name\"], iso[\"alpha-2\"]))\n",
    "\n",
    "        self.rundate = str(date.today()).replace(\"-\", \"\")\n",
    "\n",
    "    def hide_elements(self):\n",
    "        js_script = \"\"\"\\\n",
    "        document.getElementById('minimaximize').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('intro').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('intro_bg1').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('intro_bg2').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('intro_bg3').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('intro_bg4').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('map_canvas').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('address').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('adnotice').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('ad').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('controls').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('share').setAttribute(\"hidden\",\"\");\n",
    "        document.getElementById('ad').setAttribute(\"hidden\",\"\");\n",
    "        \n",
    "        elements = document.getElementsByTagName('button');\n",
    "        \n",
    "        for (element of elements) {\n",
    "        element.setAttribute(\"hidden\",\"\");\n",
    "        } \n",
    "        \"\"\"\n",
    "        self.driver.execute_script(js_script)\n",
    "\n",
    "    def get_address(self):\n",
    "        \"\"\"\n",
    "        Find the named address of the image from randomstreetview.com\n",
    "        \"\"\"\n",
    "        raw_address = self.driver.find_element(By.ID, \"address\").text\n",
    "        self.raw_address = raw_address\n",
    "        self.address = raw_address.replace(\",\", \"\")\n",
    "\n",
    "    def get_gps_from_address(self):\n",
    "        \"\"\"\n",
    "        Take an address from the scraper and return the latitude and longitude\n",
    "\n",
    "        return ex: TODO\n",
    "        \"\"\"\n",
    "        preprocessed_address = self.address\n",
    "        try:\n",
    "            gps = self.geolocator.geocode(preprocessed_address)\n",
    "            self.latitude = gps.latitude\n",
    "            self.longitude = gps.longitude\n",
    "            coordinates = (gps.latitude, gps.longitude)\n",
    "        except Exception as e:\n",
    "            # print(f\"Cannot find a gps coordinate for {self.address}\")\n",
    "            coordinates = \"_UNLABELED\"\n",
    "            self.latitude = None\n",
    "            self.longitude = None\n",
    "\n",
    "        self.coordinates = coordinates\n",
    "\n",
    "    def get_iso_alpha2_from_address(self):\n",
    "        \"\"\"\n",
    "        Take an address from the scraper and return an iso3166 country code\n",
    "        \n",
    "        return ex: TODO\n",
    "        \"\"\"\n",
    "\n",
    "        def get_country_from_address(address):\n",
    "            return address.replace(\".jpg\", \"\").split(\",\")[-1].lstrip().rstrip()\n",
    "\n",
    "        country = get_country_from_address(self.raw_address)\n",
    "\n",
    "        try:\n",
    "            iso_alpha2 = self.name_to_iso_alpha2[country]\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                iso_alpha2 = pycountry.countries.search_fuzzy(country)[0].alpha_2\n",
    "            except Exception as e:\n",
    "                iso_alpha2 = \"_UNLABELED\"\n",
    "                # print(f\"Could not match {country} to a country\")\n",
    "\n",
    "        self.iso_alpha2 = iso_alpha2\n",
    "\n",
    "    def rotate_canvas(self):\n",
    "        \"\"\"\n",
    "        Drag and click the <gm-style> elem a few times to rotate the screen ~90 degrees.\n",
    "        Credit: https://github.com/healeycodes\n",
    "        \"\"\"\n",
    "        main = self.driver.find_element(By.CLASS_NAME, \"gm-style\")\n",
    "        for _ in range(0, 3):\n",
    "            action = webdriver.common.action_chains.ActionChains(self.driver)\n",
    "\n",
    "            # drag and click along the top to avoid hitting Google UI arrows\n",
    "            action.move_to_element_with_offset(main, 250, 100).click_and_hold(\n",
    "                main\n",
    "            ).move_by_offset(250, 0).release(main).perform()\n",
    "\n",
    "    def screenshot_panoramic(self, save_location=\"../data/rsv\", num_screenshots=3):\n",
    "        \"\"\"\n",
    "        Take a screenshot of the streetview canvas.\n",
    "        \"\"\"\n",
    "\n",
    "        def update_metadata(img_filename, metadata_file_path):\n",
    "            \"\"\"\n",
    "            Helper function that updates the metadata file which contains\n",
    "            class labels \n",
    "            \"\"\"\n",
    "\n",
    "            img_labels = {\n",
    "                \"file_name\": img_filename,\n",
    "                \"country_iso_alpha2\": self.iso_alpha2,\n",
    "                \"latitude\": self.latitude,\n",
    "                \"longitude\": self.longitude,\n",
    "            }\n",
    "\n",
    "            # append labels to metadata file\n",
    "            with jsonlines.open(metadata_file_path, mode=\"a\") as appender:\n",
    "                appender.write(img_labels)\n",
    "\n",
    "        # initate\n",
    "        images = []\n",
    "        print(\n",
    "            f\"Beginning to scrape images from {self.address} from alpha2 code {self.iso_alpha2} and gps coordinates {self.coordinates}\"\n",
    "        )\n",
    "        clean_coordinate = (\n",
    "            str(self.coordinates)\n",
    "            .replace(\"(\", \"\")\n",
    "            .replace(\")\", \"\")\n",
    "            .replace(\",\", \"_\")\n",
    "            .replace(\" \", \"\")\n",
    "        )\n",
    "\n",
    "        # repeat: screenshot, save, rotate\n",
    "        for ss in range(0, num_screenshots):\n",
    "\n",
    "            # allow for screen to buffer\n",
    "            time.sleep(2)\n",
    "\n",
    "            indv_filename = f\"{self.rundate}_{self.address}_{ss}_{clean_coordinate}.png\"\n",
    "            if self.iso_alpha2 == \"_UNLABELED\":\n",
    "                raw_image_location = f\"{save_location}_indv/unlabeled/{indv_filename}\"\n",
    "                update_metadata(\n",
    "                    img_filename=indv_filename,\n",
    "                    metadata_file_path=f\"{save_location}_indv/unlabeled/metadata.jsonl\",\n",
    "                )\n",
    "            else:\n",
    "                raw_image_location = (\n",
    "                    f\"{save_location}_indv/train/{indv_filename}\"\n",
    "                )\n",
    "                update_metadata(\n",
    "                    img_filename=indv_filename,\n",
    "                    metadata_file_path=f\"{save_location}_indv/train/metadata.jsonl\",\n",
    "                )\n",
    "\n",
    "            # screenshot\n",
    "            with open(raw_image_location, \"xb\") as f:\n",
    "                canvas = WebDriverWait(self.driver, 1).until(\n",
    "                    EC.element_to_be_clickable((By.TAG_NAME, \"canvas\"))\n",
    "                )\n",
    "\n",
    "                image_data = BytesIO(canvas.screenshot_as_png)\n",
    "                image = Image.open(image_data)\n",
    "                width, height = image.size\n",
    "                # remove the left and bottom UI elements\n",
    "                cropped_image = image.crop((0, 0, width, height - 75))\n",
    "                cropped_image.save(f)\n",
    "\n",
    "            images.append(Image.open(raw_image_location))\n",
    "\n",
    "            if ss == num_screenshots - 1:\n",
    "                break\n",
    "            else:\n",
    "                self.rotate_canvas()\n",
    "\n",
    "        # combine images to panoramic\n",
    "        widths, heights = zip(*(i.size for i in images))\n",
    "        total_width = sum(widths)\n",
    "        max_height = max(heights)\n",
    "        new_im = Image.new(\"RGB\", (total_width, max_height))\n",
    "        x_offset = 0\n",
    "        for im in images:\n",
    "            new_im.paste(im, (x_offset, 0))\n",
    "            x_offset += im.size[0]\n",
    "\n",
    "        pano_filename = f\"{self.rundate}_{self.address}_{clean_coordinate}.jpg\"\n",
    "        if self.iso_alpha2 == \"_UNLABELED\":\n",
    "            new_im.save(\n",
    "                f\"{save_location}_pano/unlabeled/{pano_filename}\"\n",
    "            )\n",
    "            update_metadata(\n",
    "                img_filename=pano_filename,\n",
    "                metadata_file_path=f\"{save_location}_pano/unlabeled/metadata.jsonl\",\n",
    "            )\n",
    "        else:            \n",
    "            new_im.save(f\"{save_location}_pano/train/{pano_filename}\")\n",
    "            update_metadata(\n",
    "                img_filename=pano_filename,\n",
    "                metadata_file_path=f\"{save_location}_pano/train/metadata.jsonl\",\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from 101-375 Shot Point Dr Marquette MI 49855 USA from alpha2 code US and gps coordinates _UNLABELED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from Ciudad Pérdida 10 La Sabana 39799 Acapulco Guerrero Mexico from alpha2 code MX and gps coordinates _UNLABELED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from LU-P-2917 20 27127 Barredo Lugo Spain from alpha2 code ES and gps coordinates (43.0400603, -7.4057073)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from Otto-Hahn-Straße 3 25813 Husum Germany from alpha2 code DE and gps coordinates (54.494102, 9.0774607)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from 3299 Tambon Nong Bon Amphoe Bo Rai Chang Wat Trat 23140 Thailand from alpha2 code TH and gps coordinates _UNLABELED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from X-695 Coyhaique XI Región Chile from alpha2 code CL and gps coordinates (-45.9088235, -71.7036364)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from Unnamed Road Văluța Romania from alpha2 code RO and gps coordinates _UNLABELED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from Unnamed Road Cambodia from alpha2 code KH and gps coordinates _UNLABELED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from Unnamed Road Orkney Orkney KW17 2AG UK from alpha2 code UG and gps coordinates _UNLABELED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n",
      "/var/folders/f_/zs09ywnj0xb_3zg195l5bmz80000gn/T/ipykernel_65964/827768301.py:49: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to scrape images from Steenakkerstraat 94-120 3590 Diepenbeek Belgium from alpha2 code BE and gps coordinates (50.9249146, 5.441668)\n"
     ]
    }
   ],
   "source": [
    "#from RandomStreetViewParser import * \n",
    "\n",
    "for _ in np.arange(1):\n",
    "    try:\n",
    "        rsv = RandomStreetViewParser(driver_path='../utility/chromedriver')\n",
    "        rsv.driver.get('https://randomstreetview.com/')\n",
    "        time.sleep(1)\n",
    "        rsv.get_address()\n",
    "        rsv.hide_elements()\n",
    "        rsv.get_gps_from_address()\n",
    "        rsv.get_iso_alpha2_from_address()\n",
    "        if rsv.iso_alpha2 == '_UNLABELED':\n",
    "            # Country not clearly defined, skipping for now...\"\n",
    "            pass\n",
    "        else:\n",
    "            rsv.screenshot_panoramic(save_location = '../data/rsv')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsv.driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all empty metadata files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to label the huggingface dataset correctly, I need to have a metadata file per each country named folder.\n",
    "\n",
    "For now I can dump everything in the generic `train` folder because we can decide on that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLDER_NAME = 'rsv7'\n",
    "\n",
    "# # with open(f'../data/{FOLDER_NAME}/train/AF/metadata.jsonl', 'rb+') as filehandle:\n",
    "# #     filehandle.seek(-1, os.SEEK_END)\n",
    "# #     filehandle.truncate()\n",
    "\n",
    "# with open(f\"../data/{FOLDER_NAME}/train/AF/metadata.jsonl\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# data = [data]\n",
    "\n",
    "# data += [{'filename': \"deez\", \"latitude\": 1, \"longitude\":2, \"country_iso_alpha2\": \"nuts\"}]\n",
    "# with open(f\"../data/{FOLDER_NAME}/train/AF/metadata.jsonl\", 'w') as out:\n",
    "#     for ddict in data:\n",
    "#         jout = json.dumps(ddict) + ',/n'\n",
    "#         out.write(jout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's super complicated lets just make a listed json and then jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = 'rsv7'\n",
    "metadata_template = {}\n",
    "metadata_list = []\n",
    "\n",
    "# # create the json (only needs to be done once)\n",
    "#os.remove(f'../data/{FOLDER_NAME}/train/AF/metadata.jsonl')\n",
    "\n",
    "# with open(f'../data/{FOLDER_NAME}/train/AF/metadata.jsonl', 'w') as f:\n",
    "#     json.dump(metadata_template, f)\n",
    "\n",
    "jsontest = {\n",
    "    \"filename\": \"init.jpg\",\n",
    "    \"country\": \"None\",\n",
    "    \"latitude\": 0,\n",
    "    \"longitude\": 0,\n",
    "}\n",
    "\n",
    "# with jsonlines.open(f\"../data/{FOLDER_NAME}/train/AF/metadata.jsonl\") as reader:\n",
    "#     metadata = reader.read()\n",
    "\n",
    "with jsonlines.open(f'../data/{FOLDER_NAME}/train/AF/metadata.jsonl', mode='a') as appender:\n",
    "    appender.write(jsontest)\n",
    "\n",
    "\n",
    "# metadata_list.append(metadata)\n",
    "# jsontest = {\n",
    "#     \"filename\": \"a\",\n",
    "#     \"country\": \"US\",\n",
    "#     \"latitude\": 123.3,\n",
    "#     \"longitude\": -69.420,\n",
    "# }\n",
    "\n",
    "# metadata_list.append(jsontest)\n",
    "\n",
    "# with jsonlines.open(f\"../data/{FOLDER_NAME}/train/AF/metadata.jsonl\", 'w') as writer:\n",
    "#     writer.write_all(metadata_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert nested json to jsonl\n",
    "\n",
    "def update_metadata(img_filename, metadata_file_path):\n",
    "    \"\"\"\n",
    "    Helper function that updates the metadata file which contains\n",
    "    class labels \n",
    "    \"\"\"    \n",
    "\n",
    "    img_labels = {\n",
    "        \"filname\": img_filename,\n",
    "        \"country_iso_alpha2\": self.iso_alpha2,\n",
    "        \"latitude\": self.latitude,\n",
    "        \"longitude\": self.longitude,\n",
    "    }\n",
    "\n",
    "    # append labels to metadata file\n",
    "    with jsonlines.open(metadata_file_path, mode='a') as appender:\n",
    "        appender.write(img_labels)\n",
    "\n",
    "update_metadata(img_filename = pano_filename, metadata_file_path = f'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(indv)\n",
    "\n",
    "train\n",
    "    US\n",
    "        metadata.json\n",
    "        {self.rundate}_{self.address}_{ss}_{clean_coordinates}.png\n",
    "        {self.rundate}_{self.address}_{ss}_{clean_coordinate}.png\n",
    "    UK\n",
    "        metadata.json\n",
    "        ...\n",
    "\n",
    "unlabeled\n",
    "\n",
    "\n",
    "(pano)\n",
    "train\n",
    "    US\n",
    "        metadata.jsonl (country = YES, coordinate = MAYBE)\n",
    "        {self.rundate}_{self.address}.jpg\n",
    "    UK\n",
    "        metadata.jsonl\n",
    "        {self.rundate}_{self.address}.jpg\n",
    "    ...\n",
    "\n",
    "unlabeled\n",
    "    {self.rundate}_{self.address}.jpg\n",
    "    metadata.jsonl (country = NONE, coordinate = MAYBE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('geoguessr_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bbe3073690b1946082bee4412bfd0cd0295e0d31a62a891e416969eaed5d9fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
