{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-052ddf8e3c03abf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /Users/winsontruong/.cache/huggingface/datasets/imagefolder/default-052ddf8e3c03abf5/0.0.0/e872d3ec27c6c200a8881a4af52930df7eca3372b19aa4d0f5db74a2fded8141...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Downloading data files #3: 100%|██████████| 1/1 [00:00<00:00, 5555.37obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #4: 100%|██████████| 1/1 [00:00<00:00, 5555.37obj/s][A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #6: 100%|██████████| 1/1 [00:00<00:00, 5562.74obj/s][A\u001b[A\u001b[A\n",
      "Downloading data files #0:   0%|          | 0/2 [00:00<?, ?obj/s]\n",
      "\n",
      "Downloading data files #0: 100%|██████████| 2/2 [00:00<00:00, 4914.24obj/s]\n",
      "Downloading data files #2: 100%|██████████| 1/1 [00:00<00:00, 1481.56obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #7:   0%|          | 0/1 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading data files #7: 100%|██████████| 1/1 [00:00<00:00, 1553.45obj/s]\n",
      "Downloading data files #1: 100%|██████████| 1/1 [00:00<00:00, 1801.68obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #5: 100%|██████████| 1/1 [00:00<00:00, 5592.41obj/s][A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #10: 100%|██████████| 1/1 [00:00<00:00, 7397.36obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #9: 100%|██████████| 1/1 [00:00<00:00, 5683.34obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #8: 100%|██████████| 1/1 [00:00<00:00, 8355.19obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #11: 100%|██████████| 1/1 [00:00<00:00, 8192.00obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #12: 100%|██████████| 1/1 [00:00<00:00, 7061.12obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #15:   0%|          | 0/1 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #15: 100%|██████████| 1/1 [00:00<00:00, 3650.40obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading data files #14: 100%|██████████| 1/1 [00:00<00:00, 4739.33obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #13: 100%|██████████| 1/1 [00:00<00:00, 9892.23obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Metadata files /Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/unlabeled/metadata.jsonl and /Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/IS/metadata.jsonl have different features: ('/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/IS/metadata.jsonl', {'file_name': Value(dtype='string', id=None), 'country_iso_alpha2': Value(dtype='string', id=None), 'latitude': Value(dtype='float64', id=None), 'longitude': Value(dtype='float64', id=None)}) != {'file_name': Value(dtype='string', id=None), 'country_iso_alpha2': Value(dtype='string', id=None), 'latitude': Value(dtype='null', id=None), 'longitude': Value(dtype='null', id=None)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset2 \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mimagefolder\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                         ,data_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../data/rsv2_pano/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                         )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dataset2\u001b[39m.\u001b[39mpush_to_hub(\u001b[39m'\u001b[39m\u001b[39mstochastic/random_streetview_images\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/load.py:1698\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[1;32m   1695\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   1697\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1698\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   1699\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1700\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1701\u001b[0m     ignore_verifications\u001b[39m=\u001b[39;49mignore_verifications,\n\u001b[1;32m   1702\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   1703\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1704\u001b[0m )\n\u001b[1;32m   1706\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1707\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1708\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1709\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/builder.py:807\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m downloaded_from_gcs:\n\u001b[1;32m    802\u001b[0m     prepare_split_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    803\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfile_format\u001b[39m\u001b[39m\"\u001b[39m: file_format,\n\u001b[1;32m    804\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmax_shard_size\u001b[39m\u001b[39m\"\u001b[39m: max_shard_size,\n\u001b[1;32m    805\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs,\n\u001b[1;32m    806\u001b[0m     }\n\u001b[0;32m--> 807\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    808\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    809\u001b[0m         verify_infos\u001b[39m=\u001b[39;49mverify_infos,\n\u001b[1;32m    810\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m    811\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m    812\u001b[0m     )\n\u001b[1;32m    813\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/builder.py:1416\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verify_infos, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verify_infos, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1416\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m   1417\u001b[0m         dl_manager, verify_infos, check_duplicate_keys\u001b[39m=\u001b[39;49mverify_infos, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_splits_kwargs\n\u001b[1;32m   1418\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/builder.py:876\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verify_infos, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    874\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m    875\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 876\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[1;32m    878\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m verify_infos \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/packaged_modules/folder_based_builder/folder_based_builder.py:195\u001b[0m, in \u001b[0;36mFolderBasedBuilder._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mfor\u001b[39;00m downloaded_metadata_file, metadata_features \u001b[39min\u001b[39;00m features_per_metadata_file:\n\u001b[1;32m    194\u001b[0m     \u001b[39mif\u001b[39;00m metadata_features \u001b[39m!=\u001b[39m features_per_metadata_file[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 195\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    196\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMetadata files \u001b[39m\u001b[39m{\u001b[39;00mdownloaded_metadata_file\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mfeatures_per_metadata_file[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m have different features: \u001b[39m\u001b[39m{\u001b[39;00mfeatures_per_metadata_file[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{\u001b[39;00mmetadata_features\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    198\u001b[0m metadata_features \u001b[39m=\u001b[39m features_per_metadata_file[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m metadata_features:\n",
      "\u001b[0;31mValueError\u001b[0m: Metadata files /Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/unlabeled/metadata.jsonl and /Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/IS/metadata.jsonl have different features: ('/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/IS/metadata.jsonl', {'file_name': Value(dtype='string', id=None), 'country_iso_alpha2': Value(dtype='string', id=None), 'latitude': Value(dtype='float64', id=None), 'longitude': Value(dtype='float64', id=None)}) != {'file_name': Value(dtype='string', id=None), 'country_iso_alpha2': Value(dtype='string', id=None), 'latitude': Value(dtype='null', id=None), 'longitude': Value(dtype='null', id=None)}"
     ]
    }
   ],
   "source": [
    "dataset2 = load_dataset(\"imagefolder\"\n",
    "                        ,data_dir = \"../data/rsv2_pano/\"\n",
    "                        )\n",
    "dataset2.push_to_hub('stochastic/random_streetview_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 17/17 [00:00<00:00, 109866.21it/s]\n",
      "Using custom data configuration default-77da025f1a040da8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /Users/winsontruong/.cache/huggingface/datasets/imagefolder/default-77da025f1a040da8/0.0.0/e872d3ec27c6c200a8881a4af52930df7eca3372b19aa4d0f5db74a2fded8141...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloading data files #2: 100%|██████████| 2/2 [00:00<00:00, 8192.00obj/s]\n",
      "\n",
      "Downloading data files #1: 100%|██████████| 2/2 [00:00<00:00, 8473.34obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #4:   0%|          | 0/2 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading data files #4: 100%|██████████| 2/2 [00:00<00:00, 1974.25obj/s]\n",
      "Downloading data files #3: 100%|██████████| 2/2 [00:00<00:00, 2989.53obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #7:   0%|          | 0/2 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #7: 100%|██████████| 2/2 [00:00<00:00, 2945.44obj/s][A\u001b[A\u001b[A\n",
      "Downloading data files #6: 100%|██████████| 2/2 [00:00<00:00, 2950.62obj/s]\n",
      "Downloading data files #0: 100%|██████████| 2/2 [00:00<00:00, 12446.01obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #5: 100%|██████████| 2/2 [00:00<00:00, 9010.32obj/s][A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #8: 100%|██████████| 2/2 [00:00<00:00, 11898.73obj/s]A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #9: 100%|██████████| 2/2 [00:00<00:00, 10645.44obj/s]A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #10: 100%|██████████| 1/1 [00:00<00:00, 5236.33obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #12: 100%|██████████| 1/1 [00:00<00:00, 8128.50obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #11: 100%|██████████| 1/1 [00:00<00:00, 9238.56obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #13: 100%|██████████| 1/1 [00:00<00:00, 8338.58obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #14: 100%|██████████| 1/1 [00:00<00:00, 9915.61obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #15: 100%|██████████| 1/1 [00:00<00:00, 9532.51obj/s][A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Metadata files /Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/GR/metadata.jsonl and /Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/KH/metadata.jsonl have different features: ('/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/KH/metadata.jsonl', {'file_name': Value(dtype='string', id=None), 'country_iso_alpha2': Value(dtype='string', id=None), 'latitude': Value(dtype='float64', id=None), 'longitude': Value(dtype='float64', id=None)}) != {'file_name': Value(dtype='string', id=None), 'country_iso_alpha2': Value(dtype='string', id=None), 'latitude': Value(dtype='null', id=None), 'longitude': Value(dtype='null', id=None)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dataset2 \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mimagefolder\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         ,data_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../data/rsv2_pano/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/notebooks/upload_to_hf.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m dataset2\u001b[39m.\u001b[39mpush_to_hub(\u001b[39m'\u001b[39m\u001b[39mstochastic/random_streetview_images\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/load.py:1698\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[1;32m   1695\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   1697\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1698\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   1699\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1700\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1701\u001b[0m     ignore_verifications\u001b[39m=\u001b[39;49mignore_verifications,\n\u001b[1;32m   1702\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   1703\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1704\u001b[0m )\n\u001b[1;32m   1706\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1707\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1708\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1709\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/builder.py:807\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m downloaded_from_gcs:\n\u001b[1;32m    802\u001b[0m     prepare_split_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    803\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfile_format\u001b[39m\u001b[39m\"\u001b[39m: file_format,\n\u001b[1;32m    804\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmax_shard_size\u001b[39m\u001b[39m\"\u001b[39m: max_shard_size,\n\u001b[1;32m    805\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs,\n\u001b[1;32m    806\u001b[0m     }\n\u001b[0;32m--> 807\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    808\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    809\u001b[0m         verify_infos\u001b[39m=\u001b[39;49mverify_infos,\n\u001b[1;32m    810\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m    811\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m    812\u001b[0m     )\n\u001b[1;32m    813\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/builder.py:1416\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verify_infos, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verify_infos, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1416\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m   1417\u001b[0m         dl_manager, verify_infos, check_duplicate_keys\u001b[39m=\u001b[39;49mverify_infos, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_splits_kwargs\n\u001b[1;32m   1418\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/builder.py:876\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verify_infos, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    874\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m    875\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 876\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[1;32m    878\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m verify_infos \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geoguessr_dev/lib/python3.8/site-packages/datasets/packaged_modules/folder_based_builder/folder_based_builder.py:195\u001b[0m, in \u001b[0;36mFolderBasedBuilder._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mfor\u001b[39;00m downloaded_metadata_file, metadata_features \u001b[39min\u001b[39;00m features_per_metadata_file:\n\u001b[1;32m    194\u001b[0m     \u001b[39mif\u001b[39;00m metadata_features \u001b[39m!=\u001b[39m features_per_metadata_file[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 195\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    196\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMetadata files \u001b[39m\u001b[39m{\u001b[39;00mdownloaded_metadata_file\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mfeatures_per_metadata_file[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m have different features: \u001b[39m\u001b[39m{\u001b[39;00mfeatures_per_metadata_file[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{\u001b[39;00mmetadata_features\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    198\u001b[0m metadata_features \u001b[39m=\u001b[39m features_per_metadata_file[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m metadata_features:\n",
      "\u001b[0;31mValueError\u001b[0m: Metadata files /Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/GR/metadata.jsonl and /Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/KH/metadata.jsonl have different features: ('/Users/winsontruong/Documents/GitHub/GeoGuessr-player/GeoGuessr/data/rsv2_pano/train/KH/metadata.jsonl', {'file_name': Value(dtype='string', id=None), 'country_iso_alpha2': Value(dtype='string', id=None), 'latitude': Value(dtype='float64', id=None), 'longitude': Value(dtype='float64', id=None)}) != {'file_name': Value(dtype='string', id=None), 'country_iso_alpha2': Value(dtype='string', id=None), 'latitude': Value(dtype='null', id=None), 'longitude': Value(dtype='null', id=None)}"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "import datasets\n",
    "\n",
    "\n",
    "dataset2 = load_dataset(\"imagefolder\"\n",
    "                        ,data_dir = \"../data/rsv2_pano/\"\n",
    "                        )\n",
    "dataset2.push_to_hub('stochastic/random_streetview_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split` controls the subfolder you return. Often it's a train, test subfolder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUSTOM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "\n",
    "class RandomStreetViewConfig(datasets.BuilderConfig):\n",
    "    \"\"\"\n",
    "    BuilderConfig for RandomStreetView\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path, **kwargs):\n",
    "        super(RandomStreetViewConfig, self).__init__(version=datasets.Version(\"1.0.0\"), **kwargs)\n",
    "        self.data_path = data_path\n",
    "        \n",
    "\n",
    "class RandomStreetViewDatasetHF(datasets.GeneratorBasedBuilder):\n",
    "    \"\"\"\n",
    "    dataset of random street view images\n",
    "    \"\"\"\n",
    "\n",
    "    VERSION = datasets.Version(\"1.0.0\")\n",
    "    BUILDER_CONFIGS = [\n",
    "        datasets.BuilderConfig(\n",
    "            name=\"panoramic\",\n",
    "            version=VERSION,\n",
    "            description=\"3 angles combined into one image for a single location\",\n",
    "        ),\n",
    "        datasets.BuilderConfig(\n",
    "            name=\"raw\",\n",
    "            version=VERSION,\n",
    "            description=\"3 images at different angle per one location, used to build panoramic\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "    DEFAULT_CONFIG_NAME = \"panoramic\"\n",
    "\n",
    "    def _info(self):\n",
    "        # TODO: This method specifies the datasets.DatasetInfo object which contains informations and typings for the dataset\n",
    "        if self.config.name == \"panoramic\":  # This is the name of the configuration selected in BUILDER_CONFIGS above\n",
    "            features = datasets.Features(\n",
    "                {\n",
    "                    \"image\": datasets.Image(),\n",
    "                    \"label\": datasets.ClassLabel(names = _NAMES)\n",
    "                    # These are the features of your dataset like images, labels ...\n",
    "                }\n",
    "            )\n",
    "        else:  #if self.config.name == \"raw\":  # This is an example to show how to have different features for \"first_domain\" and \"second_domain\"\n",
    "            features = datasets.Features(\n",
    "                {  \n",
    "                    \"image\": datasets.Image(),\n",
    "                    \"label\": datasets.ClassLabel(names = _NAMES)\n",
    "                }\n",
    "            )\n",
    "        return datasets.DatasetInfo(\n",
    "            # This is the description that will appear on the datasets page.\n",
    "            description= \"\"\"\n",
    "                The random streetview images dataset are panoramic images scraped from randomstreetview.com,\n",
    "                which shows a random location accessible by Google Streetview. The dataset was designed with \n",
    "                the intent to geolocate an image purely based on its visual content.\n",
    "            \"\"\",\n",
    "            # This defines the different columns of the dataset and their types\n",
    "            features=features,  # Here we define them above because they are different between the two configurations\n",
    "            \n",
    "            # If there's a common (input, target) tuple from the features, uncomment supervised_keys line below and\n",
    "            # specify them. They'll be used if as_supervised=True in builder.as_dataset.\n",
    "            supervised_keys=(\"image\", \"label\"),\n",
    "            \n",
    "            # Homepage of the dataset for documentation\n",
    "            homepage=_HOMEPAGE,\n",
    "            # License for the dataset if available\n",
    "            license=_LICENSE,\n",
    "            # Citation for the dataset\n",
    "            citation=_CITATION,\n",
    "            task_templates=[ImageClassification(image_column=\"image\", label_column=\"label\")]\n",
    "        )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "            # TODO: This method is tasked with downloading/extracting the data and defining the splits depending on the configuration\n",
    "            # If several configurations are possible (listed in BUILDER_CONFIGS), the configuration selected by the user is in self.config.name\n",
    "\n",
    "            # dl_manager is a datasets.download.DownloadManager that can be used to download and extract URLS\n",
    "            # It can accept any type or nested list/dict and will give back the same structure with the url replaced with path to local files.\n",
    "            # By default the archives will be extracted and a path to a cached folder where they are extracted is returned instead of the archive\n",
    "            \n",
    "            #urls = _URLS[self.config.name]\n",
    "            #dl_manager.download_and_extract(urls)\n",
    "            data_dir = '../data/rsv' \n",
    "            return [\n",
    "                datasets.SplitGenerator(\n",
    "                    name=datasets.Split.TRAIN,\n",
    "                    # These kwargs will be passed to _generate_examples\n",
    "                    gen_kwargs={\n",
    "                        \"images\": dl_manager.iter_archive(data_dir),\n",
    "                        #\"filepath\": os.path.join(data_dir, \"panoramic/\"),\n",
    "                        \"split\": \"train\",\n",
    "                    },\n",
    "                ),\n",
    "\n",
    "                # TODO: Not ready yet\n",
    "                # datasets.SplitGenerator(\n",
    "                #     name=datasets.Split.VALIDATION,\n",
    "                #     # These kwargs will be passed to _generate_examples\n",
    "                #     gen_kwargs={\n",
    "                #         \"filepath\": os.path.join(data_dir, \"dev.jsonl\"),\n",
    "                #         \"split\": \"dev\",\n",
    "                #     },\n",
    "                # ),\n",
    "                # datasets.SplitGenerator(\n",
    "                #     name=datasets.Split.TEST,\n",
    "                #     # These kwargs will be passed to _generate_examples\n",
    "                #     gen_kwargs={\n",
    "                #         \"filepath\": os.path.join(data_dir, \"test.jsonl\"),\n",
    "                #         \"split\": \"test\"\n",
    "                #     },\n",
    "                # ),\n",
    "            ]\n",
    "\n",
    "    # method parameters are unpacked from `gen_kwargs` as given in `_split_generators`\n",
    "    def _generate_examples(self, filepath):\n",
    "        # TODO: This method handles input defined in _split_generators to yield (key, example) tuples from the dataset.\n",
    "        # The `key` is for legacy reasons (tfds) and is not important in itself, but must be unique for each example.\n",
    "        \n",
    "        with open(filepath, encoding=\"utf-8\") as f:\n",
    "            for key, row in enumerate(f):\n",
    "                data = json.loads(row)\n",
    "\n",
    "                if self.config.name == \"panoramic\":\n",
    "                    # Yields examples as (key, example) tuples\n",
    "                    yield key, {\n",
    "                        \"image\": data[\"image\"],\n",
    "                        \"label\": data[\"label\"],\n",
    "                    }\n",
    "                \n",
    "                else: # self.config.name == \"raw\":\n",
    "                    yield key, {\n",
    "                        \"image\": data[\"image\"],\n",
    "                        \"label\": data[\"label\"],\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.push_to_hub('stochastic/random_streetview_images')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('geoguessr_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bbe3073690b1946082bee4412bfd0cd0295e0d31a62a891e416969eaed5d9fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
